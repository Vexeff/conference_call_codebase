{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import modules.find_paras as fp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extracting Section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FactSet standard paragraph extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter file names of new factset transcript datasets\n",
    "filenames=['factset_transcripts_2024_q1.csv', 'factset_transcripts_all_years_fill.csv']\n",
    "\n",
    "# check for % or basis points in paragraphs in addition to keywords\n",
    "check_for_nums = True\n",
    "\n",
    "# get paragraph breakdown of transcripts\n",
    "fs_paras = fp.prepare_all_files(filenames=filenames, db='fs', check_for_nums=check_for_nums)\n",
    "\n",
    "print(f'Final fs_paras dataframe has {fs_paras.shape[0]} paragraphs.')\n",
    "\n",
    "# inspect before moving on\n",
    "display(fs_paras.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capital IQ standard paragraph extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting paragraph extraction...\n",
      "2004_unmatched_ciq.csv led to 0 paragraphs.\n",
      "2002_unmatched_ciq.csv led to 0 paragraphs.\n",
      "2005_unmatched_ciq.csv led to 0 paragraphs.\n",
      "2006_unmatched_ciq.csv led to 14 paragraphs.\n",
      "2007_unmatched_ciq.csv led to 29 paragraphs.\n",
      "2008_unmatched_ciq.csv led to 106 paragraphs.\n",
      "2009_unmatched_ciq.csv led to 86 paragraphs.\n",
      "2010_unmatched_ciq.csv led to 198 paragraphs.\n",
      "2011_unmatched_ciq.csv led to 680 paragraphs.\n",
      "2012_unmatched_ciq.csv led to 895 paragraphs.\n",
      "2013_unmatched_ciq.csv led to 1167 paragraphs.\n",
      "2014_unmatched_ciq.csv led to 1016 paragraphs.\n",
      "2015_unmatched_ciq.csv led to 857 paragraphs.\n",
      "2016_unmatched_ciq.csv led to 707 paragraphs.\n",
      "2017_unmatched_ciq.csv led to 345 paragraphs.\n",
      "2018_unmatched_ciq.csv led to 265 paragraphs.\n",
      "2019_unmatched_ciq.csv led to 231 paragraphs.\n",
      "2020_unmatched_ciq.csv led to 469 paragraphs.\n",
      "2021_unmatched_ciq.csv led to 682 paragraphs.\n",
      "2022_unmatched_ciq.csv led to 731 paragraphs.\n",
      "2023_unmatched_ciq.csv led to 798 paragraphs.\n",
      "2024_q1_unmatched_ciq.csv led to 152 paragraphs.\n",
      "Final ciq_paras dataframe has 9428 paragraphs.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>file_name</th>\n",
       "      <th>folder_year</th>\n",
       "      <th>CUSIP</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>Firm_name</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Date</th>\n",
       "      <th>Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>return on invested capital</td>\n",
       "      <td>I think from an overall when you look on a ret...</td>\n",
       "      <td>transcriptid_2079</td>\n",
       "      <td>2006</td>\n",
       "      <td></td>\n",
       "      <td>63194</td>\n",
       "      <td>CNET Networks, Inc.</td>\n",
       "      <td>CNET Networks Inc., Q1 2006 Earnings Call, Apr...</td>\n",
       "      <td>2006-04-24</td>\n",
       "      <td>ciq_2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IRR</td>\n",
       "      <td>With the higher ARPU and lower churn from thes...</td>\n",
       "      <td>transcriptid_2892</td>\n",
       "      <td>2006</td>\n",
       "      <td></td>\n",
       "      <td>234356</td>\n",
       "      <td>WithSecure Oyj</td>\n",
       "      <td>F-Secure Oyj, Q2 2006 Earnings Call, Aug-01-2006</td>\n",
       "      <td>2006-08-01</td>\n",
       "      <td>ciq_2892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IRR</td>\n",
       "      <td>Okay, that is fair enough. Separately, Mike, I...</td>\n",
       "      <td>transcriptid_2892</td>\n",
       "      <td>2006</td>\n",
       "      <td></td>\n",
       "      <td>234356</td>\n",
       "      <td>WithSecure Oyj</td>\n",
       "      <td>F-Secure Oyj, Q2 2006 Earnings Call, Aug-01-2006</td>\n",
       "      <td>2006-08-01</td>\n",
       "      <td>ciq_2892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IRR</td>\n",
       "      <td>When you combine those two, you have your abso...</td>\n",
       "      <td>transcriptid_2892</td>\n",
       "      <td>2006</td>\n",
       "      <td></td>\n",
       "      <td>234356</td>\n",
       "      <td>WithSecure Oyj</td>\n",
       "      <td>F-Secure Oyj, Q2 2006 Earnings Call, Aug-01-2006</td>\n",
       "      <td>2006-08-01</td>\n",
       "      <td>ciq_2892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WACC</td>\n",
       "      <td>So summing up, the financial remuneration reco...</td>\n",
       "      <td>transcriptid_2485612</td>\n",
       "      <td>2006</td>\n",
       "      <td></td>\n",
       "      <td>164534</td>\n",
       "      <td>Atlas Corp.</td>\n",
       "      <td>Seaspan Corp., Q1 2006 Earnings Call, Apr-17-2006</td>\n",
       "      <td>2006-04-17</td>\n",
       "      <td>ciq_2485612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Keyword  \\\n",
       "0  return on invested capital   \n",
       "1                         IRR   \n",
       "2                         IRR   \n",
       "3                         IRR   \n",
       "4                        WACC   \n",
       "\n",
       "                                           Paragraph             file_name  \\\n",
       "0  I think from an overall when you look on a ret...     transcriptid_2079   \n",
       "1  With the higher ARPU and lower churn from thes...     transcriptid_2892   \n",
       "2  Okay, that is fair enough. Separately, Mike, I...     transcriptid_2892   \n",
       "3  When you combine those two, you have your abso...     transcriptid_2892   \n",
       "4  So summing up, the financial remuneration reco...  transcriptid_2485612   \n",
       "\n",
       "   folder_year CUSIP   gvkey            Firm_name  \\\n",
       "0         2006         63194  CNET Networks, Inc.   \n",
       "1         2006        234356       WithSecure Oyj   \n",
       "2         2006        234356       WithSecure Oyj   \n",
       "3         2006        234356       WithSecure Oyj   \n",
       "4         2006        164534          Atlas Corp.   \n",
       "\n",
       "                                            Subtitle        Date       Report  \n",
       "0  CNET Networks Inc., Q1 2006 Earnings Call, Apr...  2006-04-24     ciq_2079  \n",
       "1   F-Secure Oyj, Q2 2006 Earnings Call, Aug-01-2006  2006-08-01     ciq_2892  \n",
       "2   F-Secure Oyj, Q2 2006 Earnings Call, Aug-01-2006  2006-08-01     ciq_2892  \n",
       "3   F-Secure Oyj, Q2 2006 Earnings Call, Aug-01-2006  2006-08-01     ciq_2892  \n",
       "4  Seaspan Corp., Q1 2006 Earnings Call, Apr-17-2006  2006-04-17  ciq_2485612  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter file names of new factset transcript datasets\n",
    "filenames=['2004_unmatched_ciq.csv',\n",
    "'2002_unmatched_ciq.csv',\n",
    "'2005_unmatched_ciq.csv',\n",
    "'2006_unmatched_ciq.csv',\n",
    "'2007_unmatched_ciq.csv',\n",
    "'2008_unmatched_ciq.csv',\n",
    "'2009_unmatched_ciq.csv',\n",
    "'2010_unmatched_ciq.csv',\n",
    "'2011_unmatched_ciq.csv',\n",
    "'2012_unmatched_ciq.csv',\n",
    "'2013_unmatched_ciq.csv',\n",
    "'2014_unmatched_ciq.csv',\n",
    "'2015_unmatched_ciq.csv',\n",
    "'2016_unmatched_ciq.csv',\n",
    "'2017_unmatched_ciq.csv',\n",
    "'2018_unmatched_ciq.csv',\n",
    "'2019_unmatched_ciq.csv',\n",
    "'2020_unmatched_ciq.csv',\n",
    "'2021_unmatched_ciq.csv',\n",
    "'2022_unmatched_ciq.csv',\n",
    "'2023_unmatched_ciq.csv',\n",
    "'2024_q1_unmatched_ciq.csv']\n",
    "\n",
    "# check for % or basis points in paragraphs in addition to keywords\n",
    "check_for_nums = True\n",
    "\n",
    "# get paragraph breakdown of transcripts\n",
    "ciq_paras = fp.prepare_all_files(filenames=filenames, db='ciq', check_for_nums=check_for_nums)\n",
    "\n",
    "print(f'Final ciq_paras dataframe has {ciq_paras.shape[0]} paragraphs.')\n",
    "\n",
    "# inspect before moving on\n",
    "ciq_paras.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refinitiv standard paragraph extraction (DEPRECATED!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter file names of new factset transcript datasets\n",
    "filenames=['2024_q1_transcripts.csv', '2023_q4_full_transcripts.csv']\n",
    "\n",
    "# check for % or basis points in paragraphs in addition to keywords\n",
    "check_for_nums = True\n",
    "\n",
    "# get paragraph breakdown of transcripts\n",
    "ref_paras = fp.prepare_all_files(filenames=filenames, db='ref', check_for_nums=check_for_nums)\n",
    "\n",
    "print(f'Final ref_paras dataframe has {ref_paras.shape[0]} paragraphs.')\n",
    "\n",
    "# inspect before moving on\n",
    "display(ref_paras.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Combination Section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine and prepare for paragraph split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22835, 10)\n"
     ]
    }
   ],
   "source": [
    "# concatenate extracted paragraphs from the different sources\n",
    "all_new_paras = pd.concat([fs_paras, ciq_paras])\n",
    "print(all_new_paras.shape)\n",
    "\n",
    "# CHANGE NAME OF FILE BEFORE RUNNING\n",
    "new_file_name = 'NEWFILENAME'\n",
    "\n",
    "# save combined paragraphs dataset\n",
    "all_new_paras.to_csv(f'./new_paras/{new_file_name}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
